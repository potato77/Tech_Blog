## 集群系统协同规划

### 前言

**背景：**

- 传统方法存在缺点，如xxx等，本研究解决该问题，或改善该问题

- 单个无人系统的局限性，因此，各种任务需要集群系统，本研究为集群无人系统提供规划算法，保证飞行安全

注：并不为了使用学习类方法而使用，从实际需求出发探求最优解



**拟解决科学问题：**

探索学习类方法在路径规划中的应用潜力，解决

- 单个无人车/机的避障、路径规划问题
- 多个无人车/机的避障、路径规划问题

注：如果多机方法并不存在通信，仅通过局部感知来避障，则也属于单机问题



**限定：**

- 无人机平台 或 多无人机平台 或 空地无人平台
- 解决规划问题，解决动态障碍物问题
- 必须是基于learning的方法

**讨论：**

- 基于强化学习就是DRL吗？还有其他方法吗
- 单机的DRL和多机的DRL研究区别在哪里？
  - 是否可以在单机DRL文章和多机DRL文章中找到结合点
- 可以按照 单机 - 多机 的思路进行
- 但是需要思考创新点是什么？
  - 前人完全没有做过
  - 方法理论上的创新
  - 工程上细节trick
  - 性能提升
  - 特殊应用场景带来的限制
  - 实现了别人从来没有做过的实验
  - 创新点：虚实结合仿真实验！



**常见缩写**

Graph Neural Network （GNN） 图神经网络

Multi-Agent Reinforcement Learning （MARL）

### 文献调研

#### multi-robot collision avoidance 多机器人路径规划综述

Effcient and collision-free navigation in multi-robot systems is fundamental to advancing mobility. The problem, generally referred to as Multi-Robot Path Planning (MRPP) or Multi-Agent Path Finding (MAPF), aims at generating collision-free paths leading robots from their origins to designated destinations. Current approaches can be classified as either coupled or decoupled, depending on the structure of the state space that is searched.

- 等价于 multi-robot path planning （MAPP）、 multi-robot path finding（MAPF） 
- coupled，集中式方法，全局最优，但难以扩展数量
- decoupled，独自规划，计算量小，次优
- 如何平衡最优性（optimality）和完整性（completeness）及计算时间仍是个开放问题。
- 学习类方法，即MARL领域

**集中式方法**

论文题目：Conflict-based search for optimal multi-agent path finding

论文题目：ODrM*: Optimal multi-robot path planning in low dimensional search spaces（2013 ICRA）

**分布式方法**

RVO系列方法，均出自北卡罗来纳大学教堂山分校（*University of North Carolina at Chapel Hill*），简称UNC。

基本每个方法都有官网，包含文档、代码等，

While these RVO-based methods are computationally efficient, the robot dynamics are not fully modeled and the robot motion is typically limited by only planning one time step ahead.但是这类方法虽然计算效率高，但是机器人动力学没有完全建模，机器人的运动通常只受到一个时间步长的限制

**论文题目：Reciprocal Velocity Obstacles for real-time multi-agent navigation**

- reciprocal velocity obstacles (RVO) 系列方法第一篇
- 官网：http://gamma.cs.unc.edu/RVO/ 

**论文题目：Reciprocal n-Body Collision Avoidance**

- optimal reciprocal collision avoidance (ORCA，属于RVO系列方法)
- 官网：https://gamma.cs.unc.edu/ORCA/

**论文题目：Cooperative Collision Avoidance for Nonholonomic Robots**

- "epsilon-cooperative collision avoidance (epsilon-CCA)方法
- 发表在TRO

**论文题目：EGO-Planner**

#### Deep reinforcement learning （DRL） for robotics综述

**论文题目：Human-level control through deep reinforcement learning**

论文信息：谷歌，2015 Nature 5k被引

- Deep reinforcement learning （DRL） 
- deep Q-network （DQN）的首次提出文章，DQN是DRL的一种

- Deep reinforcement learning for robotics 研究领域

**论文题目：Towards cognitive exploration through deep reinforcement learning for mobile robots**

论文信息：Liuming港科大，2016 

- RGBD相机作为输入，机器人作为智能体，MDP问题，DRL方法
- Gazebo环境，简单的实物实验

**论文题目：Virtual-to-real Deep Reinforcement Learning: Continuous Control of Mobile Robots for Mapless Navigation**

论文信息：Liuming港科大，2017

- 简化的激光雷达数据作为输入，机器人作为智能体，DRL方法
- Gazebo环境+实物实验

**论文题目：Autonomous Navigation of UAVs in Large-Scale Complex Environments: A Deep Reinforcement Learning Approach**

论文信息：清华团队，2019年

- 传感器原始值 to 控制指令
- POMDP问题，DRL方法
- 单机

**论文题目：Deep-Reinforcement-Learning-Based Autonomous UAV Navigation With Sparse Rewards**

论文信息：清华团队

- 未看

**论文题目：Sim-to-Real Quadrotor Landing via Sequential Deep Q-Networks and Domain Randomization**

- 期刊较差，大致看看即可

#### Multi-Agent Reinforcement Learning （MARL）多智能体强化学习综述

One of the main issues of Multi-Agent Reinforcement Learning (MARL) is instability of the learning process caused by the non-stationarity that results from having different interacting policies learning at the same time.多智能体强化学习（MARL）的一个主要问题是学习过程的不稳定性，这种不稳定性是由不同交互策略同时学习所导致的。

**论文题目：Multi-agent actor-critic for mixed cooperative-competitive environments**

论文信息：2017年NIPS 机器学习顶会 

- 未读

- We then present an adaptation of actor-critic methods that considers action policies
  of other agents and is able to successfully learn policies that require complex multiagent
  coordination.

**论文题目：Motion Planning Among Dynamic, Decision-Making Agents with Deep Reinforcement Learning**

论文信息：2018 IROS

- 未读

**论文题目：Multi-Agent Motion Planning for Dense and Dynamic Environments via Deep Reinforcement Learning**

论文信息：2020 RAL，刘老师

- 未读

**论文题目：Non-Communication Decentralized Multi-Robot Collision Avoidance in Grid Map Workspace with Double Deep Q-Network**

论文信息：2021 Sensor

- 未读，质量可能有限，至少读综述部分

**论文题目：Towards Optimally Decentralized Multi-Robot Collision Avoidance via Deep Reinforcement Learning**

论文信息：深圳机器人公司，2018 ICRA

- 综述写的不错
- 仿真+简单实验

**论文题目：Towards Optimally Decentralized Multi-Robot Collision Avoidance via Deep Reinforcement Learning**

论文信息：深圳机器人公司，2018 ICRA

**论文题目：RACE: Reinforced Cooperative Autonomous Vehicle Collision Avoidance**

论文信息：2020 IEEE trans

**论文题目：Long-Range Indoor Navigation With PRM-RL**

论文信息：2020 IEEE TRO

**论文题目：A Two-Stage Reinforcement Learning Approach for Multi-UAV Collision Avoidance Under Imperfect Sensing**

论文信息：2020 IEEE RAL

**论文题目：PRIMAL: Pathfinding via Reinforcement and Imitation Multi-Agent Learning**

论文信息：2019 IEEE RAL



#### 其他论文

论文信息：delft & eth 2020 IROS

- 提出了一个高效的通信方法来解决协同避障场景中，谁和谁以及何时进行通信的问题
- 通过MARL训练策略，选择一部分智能体进行通信，其余则不通信
- 四种通信方式对比：无通信、广播通信、基于距离的广播通信及训练后的通信方式
- decentralized POMDP问题，包括六要素：状态空间（智能体位置、速度、曾经的控制量）、观测空间（其他智能体的位置、速度、目标点）、动作空间（通信或不通信）、奖励、观测模型（能直接得到其他智能体状态，理想情况）、转移模型

**论文题目：Scaling Up Multi-agent Reinforcement Learning for Robotic Systems: Learn an Adaptive Sparse Communication Graph**

论文信息：MIT 2020 IROS

- MARL问题受限于智能体数量，通过GNN训练一种新机制，从而改善通信

**论文题目：Graph Neural Networks for Decentralized Multi-Robot Path Planning**

论文信息：剑桥大学，2020 IROS

- This work focuses on multi-robot path planning for scenarios where the robots are restricted in observation and communication range, and possess no global reference frame for localization.
- 使用基于专家数据的监督学习方法来训练模型（CBS方法）
- 提问：这个不是强化学习？ CNN+GNN

**论文题目：From Perception to Decision: A Data-driven Approach to End-to-end Motion Planning for Autonomous Ground Robots**

论文信息：2017 ICRA

- 激光雷达作为原始输入，避障

**论文题目：Agile Coordination and Assistive Collision Avoidance for Quadrotor Swarms Using Virtual Structures**

论文信息：2018 TRO

- 传统方法做的

**论文题目：Graph Policy Gradients for Large Scale Unlabeled Motion Planning with Constraints**

论文信息：2019 ICRA，kumar团队

**论文题目：Trajectory Planning for Quadrotor Swarms**

论文信息：2019 TRO

- 传统方法

**论文题目：GLAS: Global-to-Local Safe Autonomy Synthesis for Multi-Robot Motion Planning with End-to-End Learning**

论文信息：2010 IROS

### 研究内容及研究方案